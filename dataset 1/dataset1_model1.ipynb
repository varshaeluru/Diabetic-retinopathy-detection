{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "58baf4ec",
      "metadata": {
        "papermill": {
          "duration": 0.019121,
          "end_time": "2022-08-07T16:38:29.177134",
          "exception": false,
          "start_time": "2022-08-07T16:38:29.158013",
          "status": "completed"
        },
        "tags": [],
        "id": "58baf4ec"
      },
      "source": [
        "# ****Deep Computer Vision****\n",
        "\n",
        "In this guide we will learn how to peform image classification and object detection/recognition using deep computer vision with something called a convolutional neural network.\n",
        "\n",
        "The goal of our convolutional neural networks will be to classify and detect images or specific objects from within the image. We will be using image data as our features and a label for those images as our label or output.\n",
        "\n",
        "We already know how neural networks work so we can skip through the basics and move right into explaining the following concepts.\n",
        "\n",
        "*     Image Data\n",
        "*     Convolutional Layer\n",
        "*     Pooling Layer\n",
        "*     CNN Architectures\n",
        "\n",
        "The major differences I am about to see in these types of neural networks are the layers that make them up.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95c6ed99",
      "metadata": {
        "papermill": {
          "duration": 0.016015,
          "end_time": "2022-08-07T16:38:29.209522",
          "exception": false,
          "start_time": "2022-08-07T16:38:29.193507",
          "status": "completed"
        },
        "tags": [],
        "id": "95c6ed99"
      },
      "source": [
        "# Components of CNN\n",
        "\n",
        "The CNN model works in two steps: feature extraction and Classification[1]\n",
        "\n",
        "Feature Extraction is a phase where various filters and layers are applied to the images to extract the information and features out of it and once it’s done it is passed on to the next phase i.e Classification where they are classified based on the target variable of the problem.\n",
        "\n",
        "A typical CNN model looks like this:\n",
        "\n",
        "    Input layer\n",
        "    Convolution layer + Activation function\n",
        "    Pooling layer\n",
        "    Fully Connected Layer\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/75211cnn-schema1.jpg)\n",
        "\n",
        "\n",
        "Let’s learn about each layer in detail.\n",
        "\n",
        "# Input layer\n",
        "\n",
        "As the name says, it’s our input image and can be Grayscale or RGB. Every image is made up of pixels that range from 0 to 255. We need to normalize them i.e convert the range between 0 to 1  before passing it to the model.\n",
        "\n",
        "Below is the example of an input image of size 4*4 and has 3 channels i.e RGB and pixel values.\n",
        "\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/98920pixel%20image.png)\n",
        "\n",
        "\n",
        "\n",
        "# Convolution Layer\n",
        "\n",
        "The convolution layer is the layer where the filter is applied to our input image to extract or detect its features. A filter is applied to the image multiple times and creates a feature map which helps in classifying the input image. Let’s understand this with the help of an example. For simplicity, we will take a 2D input image with normalized pixels.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/57527Screenshot%20(155).png)\n",
        "\n",
        "In the above figure, we have an input image of size 6*6 and applied a filter of 3*3 on it to detect some features. In this example, we have applied only one filter but in practice, many such filters are applied to extract information from the image.\n",
        "\n",
        "The result of applying the filter to the image is that we get a Feature Map of 4*4 which has some information about the input image. Many such feature maps are generated in practical applications.\n",
        "\n",
        "Let’s get into some maths behind getting the feature map in the above image.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/89436Screenshot%20(156).png)\n",
        "\n",
        "\n",
        "\n",
        "As presented in the above figure, in the first step the filter is applied to the green highlighted part of the image, and the pixel values of the image are multiplied with the values of the filter (as shown in the figure using lines) and then summed up to get the final value.\n",
        "\n",
        "In the next step, the filter is shifted by one column as shown in the below figure. This jump to the next column or row is known as stride and in this example, we are taking a stride of 1 which means we are shifting by one column.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/47821Screenshot%20(158).png)\n",
        "\n",
        "\n",
        "Similarly, the filter passes over the entire image and we get our final Feature Map. Once we get the feature map, an activation function is applied to it for introducing nonlinearity.\n",
        "\n",
        "A point to note here is that the Feature map we get is smaller than the size of our image. As we increase the value of stride the size of the feature map decreases.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/86290Screenshot%20(159).png)\n",
        "\n",
        "This is how a filter passes through the entire image with the stride of 1\n",
        "\n",
        "# Pooling Layer\n",
        "\n",
        "The pooling layer is applied after the Convolutional layer and is used to reduce the dimensions of the feature map which helps in preserving the important information or features of the input image and reduces the computation time.\n",
        "\n",
        "Using pooling, a lower resolution version of input is created that still contains the large or important elements of the input image.\n",
        "\n",
        "The most common types of Pooling are Max Pooling and Average Pooling. The below figure shows how Max Pooling works. Using the Feature map which we got from the above example to apply Pooling. Here we are using a Pooling layer of size 2*2 with a stride of 2.\n",
        "\n",
        "The maximum value from each highlighted area is taken and a new version of the input image is obtained which is of size 2*2 so after applying Pooling the dimension of the feature map has reduced.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/30447Screenshot%20(160).png)\n",
        "\n",
        "\n",
        "# Fully Connected Layer\n",
        "\n",
        "Till now we have performed the Feature Extraction steps, now comes the Classification part. The Fully connected layer (as we have in ANN) is used for classifying the input image into a label. This layer connects the information extracted from the previous steps (i.e Convolution layer and Pooling layers) to the output layer and eventually classifies the input into the desired label.\n",
        "\n",
        "The complete process of a CNN model can be seen in the below image.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/29624cnn_banner.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ce35510",
      "metadata": {
        "papermill": {
          "duration": 0.015887,
          "end_time": "2022-08-07T16:38:29.242095",
          "exception": false,
          "start_time": "2022-08-07T16:38:29.226208",
          "status": "completed"
        },
        "tags": [],
        "id": "3ce35510"
      },
      "source": [
        "# **Diabetic Retinopathy Detection**\n",
        "****Identify signs of diabetic retinopathy in eye images****\n",
        "\n",
        "\n",
        "Diabetic retinopathy is the leading cause of blindness in the working-age population of the developed world. It is estimated to affect over 93 million people.\n",
        "\n",
        "![](https://storage.googleapis.com/kaggle-competitions/kaggle/4104/media/retina.jpg)\n",
        "\n",
        "\n",
        "The US Center for Disease Control and Prevention estimates that 29.1 million people in the US have diabetes and the World Health Organization estimates that 347 million people have the disease worldwide. Diabetic Retinopathy (DR) is an eye disease associated with long-standing diabetes. Around 40% to 45% of Americans with diabetes have some stage of the disease. Progression to vision impairment can be slowed or averted if DR is detected in time, however this can be difficult as the disease often shows few symptoms until it is too late to provide effective treatment.\n",
        "\n",
        "Currently, detecting DR is a time-consuming and manual process that requires a trained clinician to examine and evaluate digital color fundus photographs of the retina. By the time human readers submit their reviews, often a day or two later, the delayed results lead to lost follow up, miscommunication, and delayed treatment.\n",
        "\n",
        "![image.png](attachment:9624638e-0309-4b36-a6d1-ff08a88c63d8.png)\n",
        "\n",
        "Clinicians can identify DR by the presence of lesions associated with the vascular abnormalities caused by the disease. While this approach is effective, its resource demands are high. The expertise and equipment required are often lacking in areas where the rate of diabetes in local populations is high and DR detection is most needed. As the number of individuals with diabetes continues to grow, the infrastructure needed to prevent blindness due to DR will become even more insufficient.\n",
        "\n",
        "The need for a comprehensive and automated method of DR screening has long been recognized, and previous efforts have made good progress using image classification, pattern recognition, and machine learning. With color fundus photography as input, the goal of this competition is to push an automated detection system to the limit of what is possible – ideally resulting in models with realistic clinical potential.\n",
        "\n",
        "DR: Diabetic Retinopathy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b68b8b12",
      "metadata": {
        "papermill": {
          "duration": 0.016712,
          "end_time": "2022-08-07T16:38:29.274972",
          "exception": false,
          "start_time": "2022-08-07T16:38:29.258260",
          "status": "completed"
        },
        "tags": [],
        "id": "b68b8b12"
      },
      "source": [
        "# ****About Dataset****\n",
        "****About the Data****\n",
        "\n",
        "The images consist of gaussian filtered retina scan images to detect diabetic retinopathy. The original dataset is available at APTOS 2019 Blindness Detection. These images are resized into 224x224 pixels so that they can be readily used with many pre-trained deep learning models.\n",
        "\n",
        "All of the images are already saved into their respective folders according to the severity/stage of diabetic retinopathy using the train.csv file provided. You will find five directories with the respective images:\n",
        "\n",
        "****0 - No_DR****\n",
        "\n",
        "****1 - Mild****\n",
        "\n",
        "****2 - Moderate****\n",
        "\n",
        "****3 - Severe****\n",
        "\n",
        "****4 - Proliferate_DR****\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d95a8bf3",
      "metadata": {
        "papermill": {
          "duration": 0.015995,
          "end_time": "2022-08-07T16:38:29.307103",
          "exception": false,
          "start_time": "2022-08-07T16:38:29.291108",
          "status": "completed"
        },
        "tags": [],
        "id": "d95a8bf3"
      },
      "source": [
        "# ****Understanding the Stages of Diabetic Retinopathy****\n",
        "\n",
        "Elevated blood sugar, blood pressure and cholesterol levels and increased body weight are associated with uncontrolled diabetes and can damage the delicate blood vessels of the retina, causing a disease called diabetic retinopathy. In the early stages of diabetic retinopathy, vision loss may be prevented or limited; but as the condition advances, it becomes more difficult to prevent vision loss.\n",
        "\n",
        "![](https://www.elmanretina.com/wp-content/uploads/shutterstock_657947524-1024x700.jpg)\n",
        "\n",
        "****Non-Proliferative Retinopathy****\n",
        "\n",
        "Non-proliferative diabetic retinopathy is the earlier and less serious stage of the disease. Due to damage from elevated blood sugar levels, the tiny blood vessels of the retina start to swell and leak fluid and blood. The leaking causes swelling inside the retina called macular edema, which is a common cause of visual impairment in people with diabetes.\n",
        "\n",
        "As non-proliferative retinopathy advances, the blood vessels may become blocked or closed off, and new abnormal blood vessels may start to grow and form in the wrong parts of the retina. Vision is usually unaffected in the non-proliferative stages, but it is best for the retina doctor to watch these changes closely every few months to ensure it doesn’t worsen to the “proliferative” stage.\n",
        "\n",
        "****Proliferative Diabetic Retinopathy****\n",
        "\n",
        "The more serious form of the disease, proliferative diabetic retinopathy is characterized by a process known as neovascularization. When the blood vessels of the retina become blocked, the retina is deprived of the oxygen and nutrients it needs to thrive. Sensing its limited blood supply, the retina responds by growing new abnormal blood vessels in the wrong parts of the retina. But the new blood vessels are abnormal and do not provide proper blood flow. They are extremely fragile and, as they grow, can leak blood into the vitreous. Sometimes this bleeding causes visual distortions called floaters; if the bleeding is severe enough, it can partially or completely impair vision.\n",
        "\n",
        "In some cases, the formation of the new, abnormal blood vessels leads to the development of scar tissue, or fibrosis, in the retina. Scar tissue may cause the retina to wrinkle or “pucker,” or even detach from its normal position along the back of the eye, which is referred to as “tractional retinal detachment.” Depending on the complication, central vision loss can occur.\n",
        "\n",
        "Another complication to watch out for is the growth of these abnormal blood vessels blocking the drainage angle, the natural mechanism by which fluid exits the eye. If this occurs, pressure inside the eye can spike very quickly, causing neovascular angle-closure glaucoma.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efdd802a",
      "metadata": {
        "papermill": {
          "duration": 0.016336,
          "end_time": "2022-08-07T16:38:29.340170",
          "exception": false,
          "start_time": "2022-08-07T16:38:29.323834",
          "status": "completed"
        },
        "tags": [],
        "id": "efdd802a"
      },
      "source": [
        "![image.png](attachment:614f6630-d4b3-4eeb-b885-0898d127ea7b.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60644a75",
      "metadata": {
        "papermill": {
          "duration": 0.016136,
          "end_time": "2022-08-07T16:38:29.372394",
          "exception": false,
          "start_time": "2022-08-07T16:38:29.356258",
          "status": "completed"
        },
        "tags": [],
        "id": "60644a75"
      },
      "source": [
        "![](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/4e2ccbd15cc04a08c9a096424043c4aee7c4388b/2-Figure1-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afa1022",
      "metadata": {
        "id": "9afa1022"
      },
      "source": [
        "# Importing Necessary Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807325af",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:29.407554Z",
          "iopub.status.busy": "2022-08-07T16:38:29.406484Z",
          "iopub.status.idle": "2022-08-07T16:38:35.491810Z",
          "shell.execute_reply": "2022-08-07T16:38:35.490793Z"
        },
        "id": "807325af",
        "papermill": {
          "duration": 6.105731,
          "end_time": "2022-08-07T16:38:35.494278",
          "exception": false,
          "start_time": "2022-08-07T16:38:29.388547",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from tensorflow import lite\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random, os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d8a02e",
      "metadata": {
        "id": "f2d8a02e"
      },
      "source": [
        "# Train & Test Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f831246",
      "metadata": {
        "id": "7f831246"
      },
      "source": [
        "**Creating a new dictionary for the Diabetic Retinopathy classifying the **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d36144e9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:35.530723Z",
          "iopub.status.busy": "2022-08-07T16:38:35.528769Z",
          "iopub.status.idle": "2022-08-07T16:38:35.566462Z",
          "shell.execute_reply": "2022-08-07T16:38:35.565267Z"
        },
        "id": "d36144e9",
        "papermill": {
          "duration": 0.057478,
          "end_time": "2022-08-07T16:38:35.568434",
          "exception": false,
          "start_time": "2022-08-07T16:38:35.510956",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Add an additional column, mapping to the type\n",
        "df = pd.read_csv(r'/home/swamy/Documents/diabetic_retinopathy_detection_using_CNN/train.csv')\n",
        "\n",
        "diagnosis_dict_binary = {\n",
        "    0: 'No_DR',\n",
        "    1: 'DR',\n",
        "    2: 'DR',\n",
        "    3: 'DR',\n",
        "    4: 'DR'\n",
        "}\n",
        "\n",
        "diagnosis_dict = {\n",
        "    0: 'No_DR',\n",
        "    1: 'Mild',\n",
        "    2: 'Moderate',\n",
        "    3: 'Severe',\n",
        "    4: 'Proliferate_DR',\n",
        "}\n",
        "\n",
        "\n",
        "df['binary_type'] =  df['diagnosis'].map(diagnosis_dict_binary.get)\n",
        "df['type'] = df['diagnosis'].map(diagnosis_dict.get)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959c572f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:35.601828Z",
          "iopub.status.busy": "2022-08-07T16:38:35.601553Z",
          "iopub.status.idle": "2022-08-07T16:38:35.816272Z",
          "shell.execute_reply": "2022-08-07T16:38:35.815422Z"
        },
        "id": "959c572f",
        "papermill": {
          "duration": 0.233994,
          "end_time": "2022-08-07T16:38:35.818442",
          "exception": false,
          "start_time": "2022-08-07T16:38:35.584448",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df['type'].value_counts().plot(kind='barh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "018ff67b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:35.853313Z",
          "iopub.status.busy": "2022-08-07T16:38:35.852491Z",
          "iopub.status.idle": "2022-08-07T16:38:36.017521Z",
          "shell.execute_reply": "2022-08-07T16:38:36.016664Z"
        },
        "id": "018ff67b",
        "papermill": {
          "duration": 0.184793,
          "end_time": "2022-08-07T16:38:36.019495",
          "exception": false,
          "start_time": "2022-08-07T16:38:35.834702",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df['binary_type'].value_counts().plot(kind='barh')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e635d62a",
      "metadata": {
        "id": "e635d62a"
      },
      "source": [
        "# Visualizing Intel Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6275efe1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:36.054233Z",
          "iopub.status.busy": "2022-08-07T16:38:36.053964Z",
          "iopub.status.idle": "2022-08-07T16:38:36.073190Z",
          "shell.execute_reply": "2022-08-07T16:38:36.072169Z"
        },
        "id": "6275efe1",
        "papermill": {
          "duration": 0.040617,
          "end_time": "2022-08-07T16:38:36.076753",
          "exception": false,
          "start_time": "2022-08-07T16:38:36.036136",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Split into stratified train, val, and test sets\n",
        "train_intermediate, val = train_test_split(df, test_size = 0.15, stratify = df['type'])\n",
        "train, test = train_test_split(train_intermediate, test_size = 0.15 / (1 - 0.15), stratify = train_intermediate['type'])\n",
        "\n",
        "print(train['type'].value_counts(), '\\n')\n",
        "print(test['type'].value_counts(), '\\n')\n",
        "print(val['type'].value_counts(), '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e080bfc3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:36.112438Z",
          "iopub.status.busy": "2022-08-07T16:38:36.112151Z",
          "iopub.status.idle": "2022-08-07T16:38:36.119836Z",
          "shell.execute_reply": "2022-08-07T16:38:36.118989Z"
        },
        "id": "e080bfc3",
        "papermill": {
          "duration": 0.027944,
          "end_time": "2022-08-07T16:38:36.121914",
          "exception": false,
          "start_time": "2022-08-07T16:38:36.093970",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create working directories for train/val/test\n",
        "base_dir = ''\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "if os.path.exists(base_dir):\n",
        "    shutil.rmtree(base_dir)\n",
        "\n",
        "if os.path.exists(train_dir):\n",
        "    shutil.rmtree(train_dir)\n",
        "os.makedirs(train_dir)\n",
        "\n",
        "if os.path.exists(val_dir):\n",
        "    shutil.rmtree(val_dir)\n",
        "os.makedirs(val_dir)\n",
        "\n",
        "if os.path.exists(test_dir):\n",
        "    shutil.rmtree(test_dir)\n",
        "os.makedirs(test_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9943d140",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:36.156105Z",
          "iopub.status.busy": "2022-08-07T16:38:36.155852Z",
          "iopub.status.idle": "2022-08-07T16:38:54.471729Z",
          "shell.execute_reply": "2022-08-07T16:38:54.470764Z"
        },
        "id": "9943d140",
        "papermill": {
          "duration": 18.336013,
          "end_time": "2022-08-07T16:38:54.474129",
          "exception": false,
          "start_time": "2022-08-07T16:38:36.138116",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Copy images to respective working directory\n",
        "src_dir = r'gaussian_filtered_images/gaussian_filtered_images'\n",
        "for index, row in train.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['id_code'] + \".png\"\n",
        "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
        "    dstfile = os.path.join(train_dir, binary_diagnosis)\n",
        "    os.makedirs(dstfile, exist_ok = True)\n",
        "    shutil.copy(srcfile, dstfile)\n",
        "\n",
        "for index, row in val.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['id_code'] + \".png\"\n",
        "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
        "    dstfile = os.path.join(val_dir, binary_diagnosis)\n",
        "    os.makedirs(dstfile, exist_ok = True)\n",
        "    shutil.copy(srcfile, dstfile)\n",
        "\n",
        "for index, row in test.iterrows():\n",
        "    diagnosis = row['type']\n",
        "    binary_diagnosis = row['binary_type']\n",
        "    id_code = row['id_code'] + \".png\"\n",
        "    srcfile = os.path.join(src_dir, diagnosis, id_code)\n",
        "    dstfile = os.path.join(test_dir, binary_diagnosis)\n",
        "    os.makedirs(dstfile, exist_ok = True)\n",
        "    shutil.copy(srcfile, dstfile)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a949ae",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:54.609643Z",
          "iopub.status.busy": "2022-08-07T16:38:54.609081Z",
          "iopub.status.idle": "2022-08-07T16:38:55.039994Z",
          "shell.execute_reply": "2022-08-07T16:38:55.039071Z"
        },
        "id": "b3a949ae",
        "papermill": {
          "duration": 0.4838,
          "end_time": "2022-08-07T16:38:55.042285",
          "exception": false,
          "start_time": "2022-08-07T16:38:54.558485",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Setting up ImageDataGenerator for train/val/test\n",
        "\n",
        "train_path = 'train'\n",
        "val_path = 'val'\n",
        "test_path = 'test'\n",
        "\n",
        "train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224), shuffle = True)\n",
        "val_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(224,224), shuffle = True)\n",
        "test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224), shuffle = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d04a49b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:38:55.078073Z",
          "iopub.status.busy": "2022-08-07T16:38:55.077783Z",
          "iopub.status.idle": "2022-08-07T16:43:21.214139Z",
          "shell.execute_reply": "2022-08-07T16:43:21.213180Z"
        },
        "id": "7d04a49b",
        "papermill": {
          "duration": 266.156666,
          "end_time": "2022-08-07T16:43:21.216493",
          "exception": false,
          "start_time": "2022-08-07T16:38:55.059827",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "\n",
        "\"\"\"model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3,3), padding=\"valid\", input_shape=(224,224,3), activation = 'relu'),\n",
        "    layers.Conv2D(32, (3, 3), padding='valid', activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), padding=\"valid\", activation = 'relu'),\n",
        "    layers.Conv2D(64, (3,3), padding=\"valid\", activation = 'relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(128, (4,4), padding=\"valid\", activation = 'relu'),\n",
        "    layers.Conv2D(128, (4,4), padding=\"valid\", activation = 'relu'),\n",
        "    layers.Conv2D(128, (4,4), padding=\"valid\", activation = 'relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dropout(0.15),\n",
        "    layers.Dense(4, activation = 'softmax')\n",
        "])\"\"\"\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(16, (3,3), padding=\"valid\", input_shape=(224,224,3), activation = 'relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(32, (3,3), padding=\"valid\", activation = 'relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(64, (4,4), padding=\"valid\", activation = 'relu'),\n",
        "    layers.Conv2D(64, (4,4), padding=\"valid\", activation = 'relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation = 'relu'),\n",
        "    #layers.Dropout(0.15),\n",
        "    layers.Dense(2, activation = 'softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-5),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=30,\n",
        "                    validation_data=val_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf77767",
      "metadata": {
        "id": "9cf77767"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "\n",
        "visualkeras.layered_view(model, scale_xy=10, legend=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2efc560",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:43:21.497974Z",
          "iopub.status.busy": "2022-08-07T16:43:21.497096Z",
          "iopub.status.idle": "2022-08-07T16:43:23.621211Z",
          "shell.execute_reply": "2022-08-07T16:43:23.620283Z"
        },
        "id": "e2efc560",
        "papermill": {
          "duration": 2.270333,
          "end_time": "2022-08-07T16:43:23.626689",
          "exception": false,
          "start_time": "2022-08-07T16:43:21.356356",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.save('64x3-CNN.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "755164b7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:43:23.905781Z",
          "iopub.status.busy": "2022-08-07T16:43:23.905435Z",
          "iopub.status.idle": "2022-08-07T16:43:25.467514Z",
          "shell.execute_reply": "2022-08-07T16:43:25.466436Z"
        },
        "id": "755164b7",
        "papermill": {
          "duration": 1.705182,
          "end_time": "2022-08-07T16:43:25.470202",
          "exception": false,
          "start_time": "2022-08-07T16:43:23.765020",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_loss, train_acc = model.evaluate_generator(train_batches, verbose=1)\n",
        "print(\"Train_Loss: \", train_loss)\n",
        "print(\"Train_Accuracy: \", train_acc)\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate_generator(test_batches, verbose=1)\n",
        "print(\"Test_Loss: \", test_loss)\n",
        "print(\"Test_Accuracy: \", test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8198e0a7",
      "metadata": {
        "papermill": {
          "duration": 0.138913,
          "end_time": "2022-08-07T16:43:25.802315",
          "exception": false,
          "start_time": "2022-08-07T16:43:25.663402",
          "status": "completed"
        },
        "tags": [],
        "id": "8198e0a7"
      },
      "source": [
        "# ****Diabet Retinopathy Detection Section****"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c98a9e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:43:26.083274Z",
          "iopub.status.busy": "2022-08-07T16:43:26.082924Z",
          "iopub.status.idle": "2022-08-07T16:43:26.253449Z",
          "shell.execute_reply": "2022-08-07T16:43:26.252489Z"
        },
        "papermill": {
          "duration": 0.314082,
          "end_time": "2022-08-07T16:43:26.255602",
          "exception": false,
          "start_time": "2022-08-07T16:43:25.941520",
          "status": "completed"
        },
        "tags": [],
        "id": "b4c98a9e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def predict_class(path):\n",
        "    img = cv2.imread(path)\n",
        "\n",
        "    RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    RGBImg= cv2.resize(RGBImg,(224,224))\n",
        "    plt.imshow(RGBImg)\n",
        "    image = np.array(RGBImg) / 255.0\n",
        "    new_model = tf.keras.models.load_model(\"64x3-CNN.model\")\n",
        "    predict=new_model.predict(np.array([image]))\n",
        "    per=np.argmax(predict,axis=1)\n",
        "    if per==1:\n",
        "        print('No DR')\n",
        "    else:\n",
        "        print('DR')\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1dcd35d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-07T16:43:26.539834Z",
          "iopub.status.busy": "2022-08-07T16:43:26.539237Z",
          "iopub.status.idle": "2022-08-07T16:43:27.592276Z",
          "shell.execute_reply": "2022-08-07T16:43:27.591288Z"
        },
        "papermill": {
          "duration": 1.199096,
          "end_time": "2022-08-07T16:43:27.594547",
          "exception": false,
          "start_time": "2022-08-07T16:43:26.395451",
          "status": "completed"
        },
        "tags": [],
        "id": "c1dcd35d"
      },
      "outputs": [],
      "source": [
        "predict_class('/home/swamy/Documents/diabetic_retinopathy_detection_using_CNN/val/No_DR/0ce062f26edc.png')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 310.46044,
      "end_time": "2022-08-07T16:43:31.953020",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-08-07T16:38:21.492580",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}